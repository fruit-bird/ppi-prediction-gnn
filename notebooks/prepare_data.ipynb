{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NP_604391', 'P16220', '2LXT', ..., 'P51532', '2GRC', 1],\n",
       "       ['NP_000263', 'O15259', '1S1N', ..., 'P21333', '2AAV', 1],\n",
       "       ['NP_057424', 'Q8TEU7', '2D93', ..., 'P10114', '1KAO', 1],\n",
       "       ...,\n",
       "       ['NP_006182', 'Q9UQ80', '2Q8K', ..., 'P21860', '1M6B', 1],\n",
       "       ['NP_003205', 'Q99594', '5EMW', ..., 'P48147', '3DDU', 0],\n",
       "       ['NP_001955', 'P18146', '4R2A', ..., 'P53396', '3MWD', 0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "processed_dir = \"../datasets/processed/new_pts/\"\n",
    "\n",
    "ppi_dataset = pd.read_csv(\"../datasets/processed/ppi_dataset.csv\")\n",
    "npy_ar = np.array(ppi_dataset)\n",
    "npy_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Dataset as Dataset_TG\n",
    "import os\n",
    "\n",
    "\n",
    "class LabelledDataset(Dataset_TG):\n",
    "    def __init__(self, npy_file, processed_dir):\n",
    "        self.npy_ar = np.load(npy_file)\n",
    "        self.processed_dir = processed_dir\n",
    "\n",
    "        self.protein_1 = self.npy_ar[:, 2]\n",
    "        self.protein_2 = self.npy_ar[:, 5]\n",
    "\n",
    "        self.label = self.npy_ar[:, 6].astype(float)\n",
    "        self.n_samples = self.npy_ar.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        prot_1_path = os.path.join(self.processed_dir, self.protein_1[index] + \".pt\")\n",
    "        prot_2_path = os.path.join(self.processed_dir, self.protein_2[index] + \".pt\")\n",
    "\n",
    "        print(f\"First prot is {prot_1_path}\")\n",
    "        print(f\"Second prot is {prot_2_path}\")\n",
    "\n",
    "        prot_1 = torch.load(prot_1_path)\n",
    "        prot_2 = torch.load(prot_2_path)\n",
    "\n",
    "        return prot_1, prot_2, torch.tensor(self.label[index])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self)\n",
    "\n",
    "    def get(self, index):\n",
    "        return self[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LabelledDataset(npy_ar, processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Make iterables using dataloader class\n",
    "DATASET_SIZE = len(dataset)\n",
    "trainset, testset = torch.utils.data.random_split(\n",
    "    dataset,\n",
    "    [math.floor(0.8 * DATASET_SIZE), DATASET_SIZE - math.floor(0.8 * DATASET_SIZE)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4444, 1111)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "\n",
    "len(trainloader), len(testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
